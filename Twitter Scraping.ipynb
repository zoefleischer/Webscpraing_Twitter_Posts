{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------AUTHENTICATION TO TWITTER API----------------\n",
    "\n",
    "import tweepy\n",
    "\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(\"public_password\", \"private_password\")\n",
    "auth.set_access_token(\"public_token\",\"private_token\")\n",
    "\n",
    "# Create API object\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")\n",
    "\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,\n",
    "    wait_on_rate_limit_notify=True)\n",
    "\n",
    "#----------------RETRIEVE COMMENTS WITHIN TWITTER'S ALLOWED RANGE (1week/3000tweets)------------\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#spacex\",\n",
    "                           lang=\"en\",\n",
    "                           since=\"2020-04-20\", sleep_on_rate_limit=False).items():\n",
    "    print (tweet.created_at, tweet.text)\n",
    "    \n",
    "    \n",
    "#----------------SURPASSING TWEET AMOUNT LIMIT (3000 TWEETS)--------------------\n",
    "\n",
    "def tweets_to_df(searchQuery,language='',until):\n",
    "    # If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "    # else default to no lower limit, go as far back as API allows\n",
    "    sinceId = None\n",
    "    # If results only below a specific ID are, set max_id to that ID.\n",
    "    # else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "    max_id = -1\n",
    "    tweetCount = 0\n",
    "    print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "    tweets=[]\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=100,lang=language,tweet_mode='extended')\n",
    "                else:\n",
    "                     new_tweets = api.search(q=searchQuery, count=100,lang=language,since_id=sinceId,tweet_mode='extended')\n",
    "            else:\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=100,lang=language,tweet_mode='extended',\n",
    "                                            max_id=str(max_id - 1))\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, count=100,lang=language,tweet_mode='extended',\n",
    "                                            max_id=str(max_id - 1),\n",
    "                                            since_id=sinceId)\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                tweets.append(tweet._json)\n",
    "            tweetCount += len(new_tweets)\n",
    "            print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "            max_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "    print (\"Downloaded {0} tweets\".format(tweetCount))\n",
    "    return pd.DataFrame(tweets)\n",
    "\n",
    "\n",
    "def tweets_to_df(searchQuery=\"#spacex\",language='en',until=\"2020-07-02\")\n",
    "\n",
    "tweets.to_csv(\"insert path\")\n",
    "\n",
    "\n",
    "\n",
    "#---------------SURPASSING THE TIME LIMIT (1 WEEK BACK)-----------------------------\n",
    "\n",
    "import GetOldTweets3 as got\n",
    "\n",
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(\"spacex\")\\\n",
    "                                           .setSince(\"2020-06-02\")\\\n",
    "                                           .setUntil(\"2020-07-01\")\\\n",
    "\n",
    "\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "tweets\n",
    "  \n",
    "tweets.to_csv(\"insert path\")\n",
    "\n",
    "\n",
    "#------------------EXTRACTING THE INFO FROM COMMENT OBJECT-----------\n",
    "\n",
    "\n",
    "tweet_dates= [ tweet.date for tweet in tweets]\n",
    "tweet_dates_pd = pd.DataFrame(tweet_dates)\n",
    "tweet_dates_pd.to_csv(\"insert path\")\n",
    "\n",
    "tweet_text= [ tweet.text for tweet in tweets]\n",
    "tweet_text_pd= pd.DataFrame(tweet_text)\n",
    "tweet_text_pd.to_csv(\"insert path\")\n",
    "\n",
    "\n",
    "#------------------------CHANGING DATE/TIME FORMAT----------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"insert path\")\n",
    "\n",
    "df.columns=['Index', 'Date']\n",
    "df=df.drop(\"Index\",1)\n",
    "\n",
    "date_list = [ date.to_datetime for date in df['Date']]\n",
    "# date_list.dt.strftime('%m/%d/%Y')\n",
    "\n",
    "#separating date and time\n",
    "df['Time']=df['Date'].apply(lambda x: x[11:19])\n",
    "df['Date']= df['Date'].apply(lambda x: x[0:10])\n",
    "\n",
    "\n",
    "df.to_csv(\"insert path\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------COUNTING COMMENTS PER HOUR-----------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"insert path\", encoding = \"ISO-8859-2\")\n",
    "\n",
    "#turning the time into integers\n",
    "df['Time']=df['Time'].apply(lambda x: int(x[:2].replace(':','.') if len(x)==8 else int(x[:1].replace(':','.'))))\n",
    "\n",
    "# grouping by day and hour and counting comments for each hour\n",
    "grouped= df.groupby(by=[\"Date\",\"Time\"])['Comments'].count()\n",
    "\n",
    "#saving it to PC\n",
    "grouped_pd= pd.DataFrame(grouped)\n",
    "grouped_pd.to_csv(\"insert path\")\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------GETTING COMMENTS WITH SPECIFIC WORDS---------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"insert path\", encoding = \"ISO-8859-2\")\n",
    "df.columns\n",
    "\n",
    "pos_comm=[]\n",
    "\n",
    "for comment in df['0'][:7871]:\n",
    "    print(comment)\n",
    "    if type(comment) == str:\n",
    "        if \"amazing\" in comment:\n",
    "            pos_comm.append(comment)\n",
    "\n",
    "        \n",
    "pos_comm\n",
    "len(pos_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
